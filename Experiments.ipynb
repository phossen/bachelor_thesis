{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with WCDS\n",
    "This notebook contains all experiments that are done using WCDS.\n",
    "\n",
    "## 1. Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wcds.wcds import WCDS\n",
    "from wcds.clusterers import *\n",
    "from sklearn.preprocessing import minmax_scale, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import *\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import io\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering of 2D data sets\n",
    "### 2.1 Loading data sets\n",
    "In the following sections `datastream` will be the variable storing the current data set. It uses a pandas dataframe for that. The last column contains the instance's class for evaluation and should not be passed to the algorithm.\n",
    "\n",
    "By executing one of the following cells, the chosen data set will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex8\n",
    "url = \"http://www2.cs.uh.edu/~ml_kdd/restored/Complex&Diamond/Complex8.data\"\n",
    "datastream = pd.read_csv(url, names=[\"X\", \"Y\", \"Class\"], header=None)\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex9\n",
    "url = \"http://www2.cs.uh.edu/~ml_kdd/restored/Complex&Diamond/Complex9.txt\"\n",
    "datastream = pd.read_csv(url, names=[\"X\", \"Y\", \"Class\"], header=None)\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D31\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/D31.txt\"\n",
    "datastream = pd.read_csv(url, names=[\"X\", \"Y\", \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jain\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/jain.txt\"\n",
    "datastream = pd.read_csv(url, names=[\"X\", \"Y\", \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"], feature_range=(0,1))\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"], feature_range=(0,1))\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"\n",
    "datastream = pd.read_csv(url, names=[\"X\", \"Y\", \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the first rows of the data set and its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Online clustering\n",
    "The next step is to perform the online step of stream clustering with WCDS on the previous selected `datastream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parameters\n",
    "OMEGA = math.inf\n",
    "DELTA = 200\n",
    "GAMMA = 200\n",
    "BETA = 60\n",
    "EPSILON = 0.1\n",
    "µ = 0\n",
    "DIM = 2\n",
    "print_step = 100\n",
    "\n",
    "# Clusterer instance\n",
    "c_online = WCDS(\n",
    "    omega=OMEGA,\n",
    "    delta=DELTA,\n",
    "    gamma=GAMMA,\n",
    "    epsilon=EPSILON,\n",
    "    dimension=DIM,\n",
    "    beta=BETA,\n",
    "    µ=µ)\n",
    "\n",
    "# Results\n",
    "results = pd.DataFrame(columns=[\"Time Stamp\", \"Class\", \"Assigned Discriminator\", \"Number of Discriminators\"])\n",
    "\n",
    "# Online step\n",
    "for time_ in range(len(datastream)):\n",
    "    k, _ = c_online.record(list(datastream.iloc[time_])[:-1], time_)\n",
    "    results.loc[len(results)] = [time_, datastream[\"Class\"][time_], k, len(c_online.discriminators)]\n",
    "    if time_ % print_step == 0 and time_ > 0:\n",
    "        print(\"Observation: {} #Discriminators: {} Cluster Measures: {}\".format(time_, len(c_online), homogeneity_completeness_v_measure(datastream[\"Class\"][max(time_-OMEGA, 0):time_], results[\"Assigned Discriminator\"][max(time_-OMEGA, 0):time_])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional save\n",
    "c_online.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Offline clustering\n",
    "Now we perform offline clustering on the current configuration of WCDS. There are three variants, but the first one is the one presented in the original paper and therefore performs best most of the times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 2\n",
    "THRESHOLD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# MergeClustering\n",
    "\n",
    "c_offline = MergeClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "actual_clusters1 = c_offline.fit(c_online.discriminators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# MinDistanceClustering\n",
    "\n",
    "c_offline = MinDistanceClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "actual_clusters2 = c_offline.fit(c_online.discriminators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# CentroidClustering\n",
    "\n",
    "c_offline = CentroidClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "centroids = [c_online.centroid(d) for d in c_online.discriminators.values()]\n",
    "actual_clusters3 = c_offline.fit(c_online.discriminators, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Results\n",
    "The following section summarizes and visualizes the obtained results of one exemplary run.\n",
    "\n",
    "| Data set | #Instances | Dimensions | Homogenity | Completeness | V-Measure | #Microclusters | Omega | Delta | Gamma | Beta | Epsilon | Mu | Runtime Online |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Complex8 | 2551 | 2 | 0.9053588976743742 | 0.9335710366851351 | 0.9192485574153881 | 91 | Inf | 200 | 200 | 70 | 0.1 | 0 | 24min 46s |\n",
    "| Complex9 | 3031 | 2 | 0.9050691859653084 | 0.8300021530934564 | 0.8659117998655447 | 98 | Inf | 200 | 200 | 80 | 0.1 | 0 | 21min 22s |\n",
    "| D31 | 3100 | 2 | 0.9055106871046765 | 0.9517232533653724 | 0.9280420288574567 | 44 | Inf | 200 | 200 | 30 | 0.3 | 0 | 5min 24s |\n",
    "| Jain | 373 | 2 | 1.0 | 1.0 | 1.0 | 33 | Inf | 200 | 200 | 60 | 0.1 | 0 | 35.7 s |\n",
    "| Aggregation | 788 | 2 | 0.9888391642302382 | 0.9876953626611313 | 0.9882669324921871 | 38 | Inf | 200 | 200 | 50 | 0.1 | 0 | 1min 43s |\n",
    "\n",
    "Plot results of actual vs online vs offline clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_dict(i, shift=0):\n",
    "    color = \"#\"\n",
    "    random.seed(i+shift)\n",
    "    color += \"\".join(random.choices(\"0123456789ABCDEF\", k=6))\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Actual Clustering\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(datastream[\"X\"],\n",
    "            datastream[\"Y\"],\n",
    "            marker=\"o\",\n",
    "            color=[color_dict(c) for c in datastream[\"Class\"]])\n",
    "plt.axis(\"scaled\", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle(\"Actual Clustering\", fontsize=18)\n",
    "print(\"{} Classes\".format(len(np.unique(datastream[\"Class\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Online\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(datastream[\"X\"],\n",
    "            datastream[\"Y\"],\n",
    "            marker=\"o\",\n",
    "            color=[color_dict(ass) for ass in results[\"Assigned Discriminator\"]])\n",
    "plt.axis(\"scaled\", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle(\"Online Clustering\", fontsize=18)\n",
    "print(\"Found {} Microclusters\".format(len(c_online)))\n",
    "print(\"Homogenity/Completeness/V-Measure: \",\n",
    "      homogeneity_completeness_v_measure(datastream[\"Class\"], results[\"Assigned Discriminator\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Offline1\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(datastream[\"X\"],\n",
    "            datastream[\"Y\"],\n",
    "            marker=\"o\",\n",
    "            color=[color_dict(actual_clusters1[ass]) for ass in results[\"Assigned Discriminator\"]])\n",
    "plt.axis(\"scaled\", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle(\"1. Offline Clustering\", fontsize=18)\n",
    "print(\"Formed {} Clusters.\".format(len(np.unique(list(actual_clusters1.values())))))\n",
    "print(\"Homogenity/Completeness/V-Measure: \", \n",
    "      homogeneity_completeness_v_measure(datastream[\"Class\"], [actual_clusters1[ass] for ass in results[\"Assigned Discriminator\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Offline2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(datastream[\"X\"],\n",
    "            datastream[\"Y\"],\n",
    "            marker=\"o\",\n",
    "            color=[color_dict(actual_clusters2[ass]) for ass in results[\"Assigned Discriminator\"]])\n",
    "plt.axis(\"scaled\", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle(\"2. Offline Clustering\", fontsize=18)\n",
    "print(\"Formed {} Clusters.\".format(len(np.unique(list(actual_clusters2.values())))))\n",
    "print(\"Homogenity/Completeness/V-Measure: \",\n",
    "      homogeneity_completeness_v_measure(datastream[\"Class\"], [actual_clusters2[ass] for ass in results[\"Assigned Discriminator\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Offline3\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(datastream[\"X\"],\n",
    "            datastream[\"Y\"],\n",
    "            marker=\"o\",\n",
    "            color=[color_dict(actual_clusters3[ass]) for ass in results[\"Assigned Discriminator\"]])\n",
    "plt.axis(\"scaled\", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle(\"3. Offline Clustering\", fontsize=18)\n",
    "print(\"Formed {} Clusters.\".format(len(np.unique(list(actual_clusters3.values())))))\n",
    "print(\"Homogenity/Completeness/V-Measure: \",\n",
    "      homogeneity_completeness_v_measure(datastream[\"Class\"], [actual_clusters3[ass] for ass in results[\"Assigned Discriminator\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell visualizes the behavior of the online clustering over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live online clustering plot\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "ax.axis(\"scaled\", xlim=[0, 1, 0, 1])\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i in range(len(results[\"Assigned Discriminator\"])):\n",
    "    ax.scatter(datastream[\"X\"][i],\n",
    "               datastream[\"Y\"][i],\n",
    "               marker=\"o\",\n",
    "               color=color_dict(int(results[\"Assigned Discriminator\"][i])))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stream clustering\n",
    "### 3.1 Loading data streams\n",
    "In the following sections `datastream` will be the variable storing the current data stream. It uses a pandas dataframe for that. The last column contains the instance's class for evaluation and should not be passed to the algorithm.\n",
    "\n",
    "By executing one of the following cells, the chosen data stream will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transient Chess Board\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/chess/transientChessboard.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/chess/transientChessboard.labels\"\n",
    "datastream = pd.read_csv(url_data, names=[\"X\", \"Y\"], header=None, sep=\" \")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Squares\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/movingSquares/movingSquares.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/movingSquares/movingSquares.labels\"\n",
    "datastream = pd.read_csv(url_data, names=[\"X\", \"Y\"], header=None, sep=\" \")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interchanging RBF\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/rbf/interchangingRBF.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/rbf/interchangingRBF.labels\"\n",
    "datastream = pd.read_csv(url_data, names=[\"X\", \"Y\"], header=None, sep=\" \")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving RBF\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/rbf/movingRBF.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/rbf/movingRBF.labels\"\n",
    "datastream = pd.read_csv(url_data, header=None, sep=\" \")\n",
    "scaler = MinMaxScaler()\n",
    "datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed Drift\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/mixedDrift/mixedDrift.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/mixedDrift/mixedDrift.labels\"\n",
    "datastream = pd.read_csv(url_data, names=[\"X\", \"Y\"], header=None, sep=\" \")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEA Concepts\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/sea/SEA_training_data.csv\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/sea/SEA_training_class.csv\"\n",
    "datastream = pd.read_csv(url_data, header=None)\n",
    "scaler = MinMaxScaler()\n",
    "datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of Network Intrusion Detection (KDD Cup 1999)\n",
    "url = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\n",
    "header = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\",\n",
    "    \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n",
    "    \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\",\n",
    "    \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
    "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
    "    \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
    "    \"dst_host_srv_rerror_rate\", \"Class\"]\n",
    "datastream = pd.read_csv(url, names=header, header=None)\n",
    "label_encoder = LabelEncoder() \n",
    "classes = label_encoder.fit_transform(datastream[\"Class\"]) \n",
    "datastream = datastream.select_dtypes(exclude=[\"object\"])\n",
    "datastream = datastream.drop(columns=[\"land\", \"logged_in\", \"is_host_login\", \"is_guest_login\"])\n",
    "scaler = MinMaxScaler()\n",
    "datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)\n",
    "datastream[\"Class\"] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Supply Data Stream\n",
    "url = \"http://www.cse.fau.edu/~xqzhu/Stream/powersupply.arff\"\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "data, meta = arff.loadarff(io.StringIO(ftpstream.read().decode('utf-8')))\n",
    "datastream = pd.DataFrame(data)\n",
    "datastream[\"attribute0\"] = minmax_scale(datastream[\"attribute0\"])\n",
    "datastream[\"attribute1\"] = minmax_scale(datastream[\"attribute1\"])\n",
    "datastream[\"Class\"] = [int(obs) for obs in datastream[\"class\"]]\n",
    "datastream = datastream.drop(columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest Cover Type (From: https://moa.cms.waikato.ac.nz/datasets/)\n",
    "data = arff.loadarff(\"./datasets/covtypeNorm.arff\")\n",
    "datastream = pd.DataFrame(data[0])\n",
    "labels = datastream[\"class\"].astype(int)\n",
    "datastream = datastream.select_dtypes(exclude=\"O\")\n",
    "datastream[\"Class\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the first rows of the data stream and its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Clustering\n",
    "This part contains the online and offline clustering of the loaded data stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parameters\n",
    "OMEGA = 250\n",
    "DELTA = 50\n",
    "GAMMA = 50\n",
    "BETA = 40\n",
    "EPSILON = 0.2\n",
    "µ = 0.5\n",
    "DIM = len(datastream.iloc[0])-1\n",
    "print_step = 200\n",
    "\n",
    "# Clusterer instance\n",
    "c_online = WCDS(\n",
    "    omega=OMEGA,\n",
    "    delta=DELTA,\n",
    "    gamma=GAMMA,\n",
    "    epsilon=EPSILON,\n",
    "    dimension=DIM,\n",
    "    beta=BETA,\n",
    "    µ=µ)\n",
    "\n",
    "# Lists\n",
    "results = pd.DataFrame(columns=[\"Time Stamp\", \"Class\", \"Assigned Discriminator\", \"Number of Discriminators\",\n",
    "                                \"Homogenity\", \"Completeness\", \"V-Measure\"])\n",
    "discriminator_lifespan = dict()\n",
    "\n",
    "# Online clustering\n",
    "for time_ in range(len(datastream)):\n",
    "    k, deleted_discriminators = c_online.record(list(datastream.iloc[time_])[:-1], time_)\n",
    "    if k not in discriminator_lifespan:\n",
    "        discriminator_lifespan[k] = [c_online.discriminators[k].creation_time, None]\n",
    "    for id_ in deleted_discriminators:\n",
    "        discriminator_lifespan[id_][1] = time_\n",
    "    current_evaluation = homogeneity_completeness_v_measure(datastream[\"Class\"][max(time_-OMEGA, 0):time_], list(results[\"Assigned Discriminator\"][max(time_-OMEGA, 0):time_]))\n",
    "    results.loc[len(results)] = [time_, datastream[\"Class\"][time_], k, len(c_online.discriminators), current_evaluation[0], current_evaluation[1], current_evaluation[2]]\n",
    "    if time_ % print_step == 0 and time_ > 0:\n",
    "        print(\"Observation: {} #Discriminators: {} Cluster Measures: {}\".format(time_, len(c_online), current_evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"TCB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results CSV files\n",
    "results.to_csv(\"./results/\" + NAME + \"_results.csv\", index_label=False)\n",
    "discr_lifespan = pd.DataFrame(columns=[\"Discriminator ID\", \"Birth\", \"Death\"])\n",
    "keys = list(discriminator_lifespan.keys())\n",
    "births = [i[0] for i in discriminator_lifespan.values()]\n",
    "deaths = [i[1] for i in discriminator_lifespan.values()]\n",
    "for i in range(len(discriminator_lifespan)):\n",
    "    discr_lifespan.loc[len(discr_lifespan)] = [keys[i], births[i], deaths[i]]\n",
    "discr_lifespan.to_csv(\"./results/\" + NAME + \"_discriminator_life_spans.csv\", index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results stored a CSV file\n",
    "results = pd.read_csv(\"./results/\" + NAME + \"_results.csv\")\n",
    "discr_lifespan = pd.read_csv(\"./results/\" + NAME + \"_discriminator_life_spans.csv\")\n",
    "discriminator_lifespan = dict()\n",
    "for i in range(len(discr_lifespan)):\n",
    "    death = None if np.isnan(discr_lifespan[\"Death\"][i]) else discr_lifespan[\"Death\"][i]\n",
    "    discriminator_lifespan[discr_lifespan[\"Discriminator ID\"][i]] = [discr_lifespan[\"Birth\"][i], death]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Results\n",
    "Visualisations and results of the experiments.\n",
    "\n",
    "| Data stream | #Instances | #Numerical Features | Omega | Delta | Gamma | Beta | Epsilon | Mu | Runtime Online |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| TCB | 200000 | 2 | 250 | 50 | 50 | 50 | 0.1 | 1 | 1h 36min 48s |\n",
    "| Moving RBF | 200000 | 10 | 500 | 50 | 50 | 50 | 0.1 | 1 | 5h 30min 15s |\n",
    "| NID | 494021 | 34 | 1000 | 50 | 50 | 68 | 0.1 | 1 | 57min 45s |\n",
    "| FCT | 581012 | 10 | 1000 | 50 | 50 | 70 | 0.1 | 1 | ~28h |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set active discriminator's death to current time for plotting\n",
    "for discr in discriminator_lifespan.values():\n",
    "    if discr[1] is None or np.isnan(discr[1]):\n",
    "        discr[1] = time_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color management\n",
    "def color_dict(i, shift=8765):\n",
    "    color = \"#\"\n",
    "    random.seed(i+shift)\n",
    "    color += \"\".join(random.choices(\"0123456789ABCDEF\", k=6))\n",
    "    return color\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate most absorbed class and thus color for every discriminator\n",
    "discr_colors_by_id = dict()\n",
    "for discr_id in np.unique(results[\"Assigned Discriminator\"]):\n",
    "    classes = [datastream[\"Class\"][i] for i in range(len(results)) if results[\"Assigned Discriminator\"][i] == discr_id]\n",
    "    discr_colors_by_id[discr_id] = color_dict(most_common(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinlge plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator life spans\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "for i in discriminator_lifespan:\n",
    "    birth = int(discriminator_lifespan[i][0])\n",
    "    death = int(discriminator_lifespan[i][1])\n",
    "    plt.plot(range(birth, death), [i for _ in range(birth, death)], color=discr_colors_by_id[i])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Discriminator ID\")\n",
    "plt.savefig(NAME + \"_\" + str(OMEGA) + \"_\" + str(time_) +\"_DLS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class life spans\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "for i in np.unique(datastream[\"Class\"]):\n",
    "    plt.scatter([k for k, j in enumerate(datastream[\"Class\"][:time_]) if j == i], [i for j in datastream[\"Class\"][:time_] if j == i], s=1, color=color_dict(i))\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.savefig(NAME + \"_\" + str(OMEGA) + \"_\" + str(time_) +\"_CLS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purity\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(dpi=200) \n",
    "plt.plot(range(time_), [i for i in results[\"Homogenity\"][:time_]])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Purity\")\n",
    "plt.savefig(NAME + \"_\" + str(OMEGA) + \"_\" + str(time_) +\"_P.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Discriminators vs #Classes in sliding window\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax1 = plt.subplots(dpi=200)\n",
    "ax1.plot(results[\"Number of Discriminators\"][:time_], color=\"blue\", alpha=.5)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot([len(np.unique(datastream[\"Class\"][max(0,i-OMEGA):i])) for i in range(time_)], color=\"orange\", alpha=.5)\n",
    "ax1.set_xlabel(\"Time\")\n",
    "ax1.set_ylabel(\"# Discriminators\", color=\"blue\", alpha=.5)\n",
    "ax2.set_ylabel(\"# Classes in SW\", color=\"orange\", alpha=.5)\n",
    "plt.savefig(NAME + \"_\" + str(OMEGA) + \"_\" + str(time_) +\"_DC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class life spans and discriminator life spans\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots(2, dpi=200)\n",
    "axs[1].set_xlabel(\"Time\")\n",
    "axs[1].set_ylabel(\"Class\")\n",
    "axs[0].set_ylabel(\"Discriminator ID\")\n",
    "for i in discriminator_lifespan:\n",
    "    birth = int(discriminator_lifespan[i][0])\n",
    "    death = int(discriminator_lifespan[i][1])\n",
    "    axs[0].plot(range(birth, death), [i for _ in range(birth, death)], color=discr_colors_by_id[i])\n",
    "for i in np.unique(datastream[\"Class\"]):\n",
    "    axs[1].scatter([k for k, j in enumerate(datastream[\"Class\"][:time_]) if j == i], [i for j in datastream[\"Class\"][:time_] if j == i], s=1, color=color_dict(i))\n",
    "fig.savefig(NAME + \"_\" + str(OMEGA) + \"_\" + str(time_) +\"_CLSDLS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Discriminators, #Classes, Purity\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots(2, dpi=200)\n",
    "ax3 = axs[0].twinx()\n",
    "axs[1].set_xlabel(\"Time\")\n",
    "axs[1].set_ylabel(\"Purity\")\n",
    "axs[0].set_ylabel(\"# Discriminators\", color=\"blue\", alpha=.5)\n",
    "ax3.set_ylabel(\"# Classes in SW\", color=\"orange\", alpha=.5)\n",
    "axs[0].plot(results[\"Number of Discriminators\"][:time_], color=\"blue\", alpha=.5)\n",
    "ax3.plot([len(np.unique(datastream[\"Class\"][max(0,i-OMEGA):i])) for i in range(time_)], color=\"orange\", alpha=.5)\n",
    "axs[1].plot(range(0,len(results[\"Number of Discriminators\"][:time_])), [i for i in results[\"Homogenity\"][:time_]])\n",
    "fig.savefig(NAME + \"_\" + str(OMEGA) + \"_\" + str(time_) +\"_DCP.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Live Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live plot of the sliding windows, only works for 2D data streams like TCB\n",
    "%matplotlib notebook\n",
    "\n",
    "MAX = 10000\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1)\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for window in range(0, MAX-OMEGA, OMEGA):\n",
    "    ax.clear()\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.scatter(datastream[\"X\"][window:window+OMEGA], datastream[\"Y\"][window:window+OMEGA], color=[color_dict(datastream[\"Class\"][i]) for i in range(window,window+OMEGA)])\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
