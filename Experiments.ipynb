{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with WCDS\n",
    "This notebook contains all experiments that are done using WCDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wcds.wcds import WCDS\n",
    "from wcds.clusterers import AgglomerativeClustering\n",
    "from sklearn.preprocessing import minmax_scale, MinMaxScaler\n",
    "from sklearn.metrics import *\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "In the following sections `datastream` will be the variable storing the current datastream. It uses a pandas dataframe for that.\n",
    "\n",
    "By executing one of the following cells, the chosen dataset/-stream will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex8\n",
    "url = \"http://www2.cs.uh.edu/~ml_kdd/restored/Complex&Diamond/Complex8.data\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None)\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex9\n",
    "url = \"http://www2.cs.uh.edu/~ml_kdd/restored/Complex&Diamond/Complex9.txt\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None)\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D31\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/D31.txt\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jain\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/jain.txt\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomeration\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest Cover Type\n",
    "data = arff.loadarff('../Datasets/covtypeNorm.arff')\n",
    "datastream = pd.DataFrame(data[0])\n",
    "labels = datastream[\"class\"].astype(int)\n",
    "datastream = datastream.select_dtypes(exclude=\"O\")\n",
    "datastream[\"Class\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of Network Intrusion Detection (KDD Cup 1999)\n",
    "url = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\n",
    "header = [\"class\",\n",
    "    \"duration\",\n",
    "    \"protocol_type\",\n",
    "    \"service\",\n",
    "    \"flag\",\n",
    "    \"src_bytes\",\n",
    "    \"dst_bytes\",\n",
    "    \"land\",\n",
    "    \"wrong_fragment\",\n",
    "    \"urgent\",\n",
    "    \"hot\",\n",
    "    \"num_failed_logins\",\n",
    "    \"logged_in\",\n",
    "    \"num_compromised\",\n",
    "    \"root_shell\",\n",
    "    \"su_attempted\",\n",
    "    \"num_root\",\n",
    "    \"num_file_creations\",\n",
    "    \"num_shells\",\n",
    "    \"num_access_files\",\n",
    "    \"num_outbound_cmds\",\n",
    "    \"is_host_login\",\n",
    "    \"is_guest_login\",\n",
    "    \"count\",\n",
    "    \"srv_count\",\n",
    "    \"serror_rate\",\n",
    "    \"srv_serror_rate\",\n",
    "    \"rerror_rate\",\n",
    "    \"srv_rerror_rate\",\n",
    "    \"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\n",
    "    \"srv_diff_host_rate\",\n",
    "    \"dst_host_count\",\n",
    "    \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\n",
    "    \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\",\n",
    "    \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\n",
    "    \"dst_host_srv_rerror_rate\"]\n",
    "datastream = pd.read_csv(url, header=None)\n",
    "#datastream = datastream.select_dtypes(exclude=[\"object\"])\n",
    "#scaler = MinMaxScaler()\n",
    "#datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "datastream = pd.DataFrame(sklearn.datasets.fetch_kddcup99())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream = datastream.select_dtypes(exclude=\"object\")\n",
    "datastream.drop(columns=[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gas mixture dataset CO2\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Gas mixture dataset ETHYLNEE\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM KNN DATASETS\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first rows of the dataset and its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online clustering\n",
    "The next step, is to perform the online step of stream clustering with WCDS on the previous selected `datastream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parameters\n",
    "OMEGA = 1000\n",
    "DELTA = 100\n",
    "GAMMA = 100\n",
    "EPSILON = 0.7\n",
    "DIM = len(datastream.iloc[0])-1\n",
    "µ = 0.5\n",
    "\n",
    "c_online = WCDS(\n",
    "    omega=OMEGA,\n",
    "    delta=DELTA,\n",
    "    gamma=GAMMA,\n",
    "    epsilon=EPSILON,\n",
    "    dimension=DIM,\n",
    "    µ=µ)\n",
    "\n",
    "c_offline = AgglomerativeClustering()\n",
    "\n",
    "assigned_discriminators = []\n",
    "time_ = 0\n",
    "for i in range(len(datastream)):\n",
    "    if i > 0 and i % 200 == 0:\n",
    "        print(\"Instance: {} Number of discriminators: {}\".format(i, len(c_online.discriminators)))\n",
    "        print(homogeneity_completeness_v_measure(datastream[\"Class\"][max(0,i-OMEGA):i], assigned_discriminators[max(0,i-OMEGA):i]))\n",
    "        actual_clusters = c_offline.fit(c_online.discriminators, n_clusters=7)\n",
    "        print(homogeneity_completeness_v_measure(datastream[\"Class\"][max(0,i-OMEGA):i], [return_correct(cluster, actual_clusters) for cluster in assigned_discriminators[max(0,i-OMEGA):i]]))\n",
    "    k = c_online.record(list(datastream.iloc[i])[:-1], time_)\n",
    "    time_ += 1\n",
    "    assigned_discriminators.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional save\n",
    "c_online.save(\"wcds.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline clustering\n",
    "Now we perform offline clustering on the current configuration of WCDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "N_CLUSTERS = None\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "c_offline = AgglomerativeClustering()\n",
    "actual_clusters = c_offline.fit(c_online.discriminators, n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results and evaluate clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_discriminators = []\n",
    "time_ = 0\n",
    "\n",
    "for x, y in zip(datastream[\"X\"], datastream[\"Y\"]):\n",
    "    k = c_online.record((x, y), time_)\n",
    "    time_ += 1\n",
    "    predicted_discriminators.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize color list\n",
    "number_of_colors = len(c_online.discriminators)\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors)]\n",
    "color_dict = {key: value for (key, value) in enumerate(colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_correct(index, clustering):\n",
    "    # Returns correct offline cluster for given discriminator\n",
    "    for i in range(len(clustering)):\n",
    "        if index in clustering[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results of online vs offline clustering\n",
    "%matplotlib inline\n",
    "\n",
    "# Online\n",
    "plt.figure(1, figsize=(6,6))\n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    plt.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[int(k)])\n",
    "    plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "plt.suptitle('Online Clustering', fontsize=18)\n",
    "    \n",
    "# Offline\n",
    "plt.figure(2, figsize=(6,6))        \n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    correct = return_correct(k, actual_clusters)\n",
    "    plt.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[correct])\n",
    "plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "plt.suptitle('Offline Clustering', fontsize=18)\n",
    "    \n",
    "print(\"Found {} Microclusters and formed {} Clusters.\".format(len(c_online.discriminators), len(actual_clusters)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Homogeneity, Completeness, V-Measure of clusterings\n",
    "print(\"Homogeneity, Completeness, V-Measure\")\n",
    "\n",
    "# Online\n",
    "print(\"Online: \", homogeneity_completeness_v_measure(datastream[\"Class\"], assigned_discriminators))\n",
    "\n",
    "# Offline\n",
    "print(\"Offline: \", homogeneity_completeness_v_measure(datastream[\"Class\"], [return_correct(assigned_discriminators[i], actual_clusters) for i in range(len(assigned_discriminators))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell visualizes the behavior of the online clustering over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live online clustering plot\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "ax.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    ax.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[int(k)])\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show discriminator bubble\n",
    "from matplotlib import cm\n",
    "cm_subsection = np.linspace(0.0, 1.0, 1000)\n",
    "colormap = cm.get_cmap(\"Greys\")\n",
    "colors = [colormap(x) for x in cm_subsection]\n",
    "\n",
    "def plot_discriminator(c_id, step=0.01):\n",
    "    points = []\n",
    "    border = []\n",
    "    \n",
    "    for i in np.arange(0,1,step):\n",
    "        for j in np.arange(0,1,step):\n",
    "            matching_rate = c_online.discriminators[c_id].matching(c_online.addressing((i,j)))\n",
    "            c = colors[round(matching_rate*999)]\n",
    "            if abs(c_online.epsilon - matching_rate) < 0.015:\n",
    "                border.append((((i,j), \"black\")))\n",
    "            points.append(((i,j), c))\n",
    "    # Plot heat map\n",
    "    plt.scatter([point[0][0] for point in points], [point[0][1] for point in points], marker=\"s\", s=1, c=[point[1] for point in points])\n",
    "    # Plot epsilon border\n",
    "    plt.scatter([point[0][0] for point in border], [point[0][1] for point in border], marker=\"o\", s=1, c=[point[1] for point in border])\n",
    "    # Plot points assigned to discriminator\n",
    "    plt.scatter([datastream[\"X\"][i] for i in range(len(assigned_discriminators)) if assigned_discriminators[i] == c_id],\n",
    "                [datastream[\"Y\"][i] for i in range(len(assigned_discriminators)) if assigned_discriminators[i] == c_id],\n",
    "                marker=\"X\", s=2, color=\"white\")\n",
    "    plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "    plt.colorbar(colors)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_descision_boundaries(step=0.01):\n",
    "    points = []\n",
    "    \n",
    "    for i in np.arange(0,1,step):\n",
    "        for j in np.arange(0,1,step):\n",
    "            matching_rate = c_online.discriminators[c_id].matching(c_online.addressing((i,j)))\n",
    "            c = colors[round(matching_rate*999)]\n",
    "            if abs(c_online.epsilon - matching_rate) < 0.015:\n",
    "                border.append((((i,j), \"black\")))\n",
    "            points.append(((i,j), c))\n",
    "    # Plot points assigned to discriminator\n",
    "    plt.scatter([datastream[\"X\"][i] for i in range(len(assigned_discriminators)) if assigned_discriminators[i] == c_id],\n",
    "                [datastream[\"Y\"][i] for i in range(len(assigned_discriminators)) if assigned_discriminators[i] == c_id],\n",
    "                marker=\"X\", s=2, color=\"white\")\n",
    "    plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "    plt.colorbar(colors)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(c_online.discriminators)):\n",
    "    plot_discriminator(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
