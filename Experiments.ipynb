{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with WCDS\n",
    "This notebook contains all experiments that are done using WCDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wcds.wcds import WCDS\n",
    "from wcds.clusterers import *\n",
    "from sklearn.preprocessing import minmax_scale, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import *\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "In the following sections `datastream` will be the variable storing the current datastream. It uses a pandas dataframe for that. The last column contains the instance's class.\n",
    "\n",
    "By executing one of the following cells, the chosen dataset/-stream will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex8\n",
    "url = \"http://www2.cs.uh.edu/~ml_kdd/restored/Complex&Diamond/Complex8.data\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None)\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex9\n",
    "url = \"http://www2.cs.uh.edu/~ml_kdd/restored/Complex&Diamond/Complex9.txt\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None)\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D31\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/D31.txt\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jain\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/jain.txt\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomeration\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"\n",
    "datastream = pd.read_csv(url, names=['X', 'Y', \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest Cover Type\n",
    "data = arff.loadarff('../Datasets/covtypeNorm.arff')\n",
    "datastream = pd.DataFrame(data[0])\n",
    "labels = datastream[\"class\"].astype(int)\n",
    "datastream = datastream.select_dtypes(exclude=\"O\")\n",
    "datastream[\"Class\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of Network Intrusion Detection (KDD Cup 1999)\n",
    "url = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\n",
    "header = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\",\n",
    "    \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n",
    "    \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\",\n",
    "    \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
    "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
    "    \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
    "    \"dst_host_srv_rerror_rate\", \"Class\"]\n",
    "datastream = pd.read_csv(url, names=header, header=None)\n",
    "label_encoder = LabelEncoder() \n",
    "classes = label_encoder.fit_transform(datastream['Class']) \n",
    "datastream = datastream.select_dtypes(exclude=[\"object\"])\n",
    "datastream = datastream.drop(columns=[\"land\", \"logged_in\", \"is_host_login\", \"is_guest_login\"])\n",
    "scaler = MinMaxScaler()\n",
    "datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)\n",
    "datastream[\"Class\"] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEA Concepts\n",
    "datastream = pd.read_csv(\"../Datasets/sea.data\", header=None)\n",
    "labels = datastream.iloc[:, 3]\n",
    "datastream = datastream.drop(columns=[3])\n",
    "scaler = MinMaxScaler()\n",
    "datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)\n",
    "datastream[\"Class\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gas mixture dataset CO2\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gas mixture dataset ETHYLEN\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM KNN DATA SETS\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first rows of the dataset and its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online clustering\n",
    "The next step, is to perform the online step of stream clustering with WCDS on the previous selected `datastream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminators: 33 Cluster Measures: (0.8977685614554353, 0.48063295384046356, 0.6260834027954487)\n",
      "Number of discriminators: 40 Cluster Measures: (0.9417817899995202, 0.4887742861626767, 0.6435521540168304)\n",
      "Number of discriminators: 46 Cluster Measures: (0.9282749504307852, 0.45350682483039345, 0.6093278010703023)\n",
      "Number of discriminators: 53 Cluster Measures: (0.932377152856411, 0.45714165505793736, 0.6134907024896642)\n",
      "Number of discriminators: 55 Cluster Measures: (0.9551455380718835, 0.4844111278966982, 0.6428133582245492)\n",
      "Number of discriminators: 57 Cluster Measures: (0.9478248352369664, 0.4686261586274641, 0.6271667901153254)\n",
      "Number of discriminators: 59 Cluster Measures: (0.9484857065689452, 0.46907209426205504, 0.6277108086839298)\n",
      "Number of discriminators: 63 Cluster Measures: (0.9285219739233599, 0.44559712807081564, 0.6021992188747662)\n",
      "Number of discriminators: 65 Cluster Measures: (0.9442929300537455, 0.46567145629392165, 0.6237466253246965)\n",
      "Number of discriminators: 68 Cluster Measures: (0.9544519763494209, 0.44921170778013797, 0.6109027499075446)\n",
      "Number of discriminators: 71 Cluster Measures: (0.9444038226468007, 0.45473176605318033, 0.6138796291195505)\n",
      "Number of discriminators: 72 Cluster Measures: (0.9670484136831627, 0.47182120962559165, 0.6342116685475284)\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parameters\n",
    "OMEGA = math.inf\n",
    "DELTA = 50\n",
    "GAMMA = 200\n",
    "EPSILON = 0.5\n",
    "DIM = len(datastream.iloc[0])-1\n",
    "µ = 1\n",
    "\n",
    "# Clusterer instance\n",
    "c_online = WCDS(\n",
    "    omega=OMEGA,\n",
    "    delta=DELTA,\n",
    "    gamma=GAMMA,\n",
    "    epsilon=EPSILON,\n",
    "    dimension=DIM,\n",
    "    µ=µ)\n",
    "\n",
    "assigned_discriminators = []\n",
    "number_discriminators = []\n",
    "time_ = 0\n",
    "\n",
    "for i in range(len(datastream)):\n",
    "    k = c_online.record(list(datastream.iloc[i])[:-1], time_)\n",
    "    number_discriminators.append(len(c_online.discriminators))\n",
    "    assigned_discriminators.append(k)\n",
    "    time_ += 1\n",
    "    if i > 0 and i % 200 == 0:\n",
    "        print(\"Number of discriminators: {} Cluster Measures: {}\".format(len(c_online), homogeneity_completeness_v_measure(datastream[\"Class\"][i-200:i], assigned_discriminators[i-200:i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional save\n",
    "c_online.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline clustering\n",
    "Now we perform offline clustering on the current configuration of WCDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 8\n",
    "THRESHOLD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# MergeClustering\n",
    "\n",
    "c_offline = MergeClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "actual_clusters1 = c_offline.fit(c_online.discriminators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# MinDistanceClustering\n",
    "\n",
    "c_offline = MinDistanceClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "actual_clusters2 = c_offline.fit(c_online.discriminators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# CentroidClustering\n",
    "\n",
    "c_offline = CentroidClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "centroids = [c_online.centroid(d) for d in c_online.discriminators.values()]\n",
    "actual_clusters3 = c_offline.fit(c_online.discriminators, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results and evaluate clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize color list\n",
    "number_of_colors = len(c_online.discriminators)\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors)]\n",
    "color_dict = {key: value for (key, value) in enumerate(colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_correct(index, clustering):\n",
    "    # Returns correct offline cluster for given discriminator\n",
    "    for i in range(len(clustering)):\n",
    "        if index in clustering[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRASiW\n",
    "drasiw = []\n",
    "for d in c_online.discriminators.values():\n",
    "    drasiw.extend(d.drasiw(c_online.seed, c_online.dimension, c_online.gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot centroids\n",
    "%matplotlib inline\n",
    "\n",
    "c_id=0\n",
    "\n",
    "plt.figure(5, figsize=(6,6))\n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    if k == c_id:\n",
    "        plt.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[int(k)])\n",
    "plt.scatter([d[0] for d in drasiw], [d[1] for d in drasiw], marker=\"o\", s=100, color=\"red\")\n",
    "plt.scatter([centroid[0] for centroid in centroids], [centroid[1] for centroid in centroids], marker=\"x\", s=100, color=\"cyan\")\n",
    "plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "plt.suptitle('Centroids', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot discriminator areas\n",
    "from matplotlib import cm\n",
    "color_maps = [\"Greens\", \"Purples\", \"Reds\", \"Blues\", \"Oranges\"]\n",
    "\n",
    "def plot_areas(discr_ids):\n",
    "\n",
    "    # Plotting\n",
    "    step = 0.01\n",
    "    colormaps = [cm.get_cmap(colorm) for colorm in color_maps]\n",
    "    points = []\n",
    "    \n",
    "    for enum, id_ in enumerate(discr_ids):\n",
    "        for i in np.arange(0, 1, step):\n",
    "            for j in np.arange(0, 1, step):\n",
    "                matching_rate = c_online.discriminators[id_].matching(\n",
    "                    c_online.addressing((i, j)))\n",
    "                c = colormaps[enum](matching_rate)\n",
    "                points.append(((i, j), c))\n",
    "        plt.scatter([point[0][0] for point in points],\n",
    "                              [point[0][1] for point in points],\n",
    "                              marker=\"s\",\n",
    "                              s=1.5,\n",
    "                              c=[point[1] for point in points], alpha=1./len(discr_ids))\n",
    "    #fig.canvas.draw()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot discriminator epsilon areas\n",
    "def plot_epsilon_areas(discr_ids):\n",
    "    # Plotting\n",
    "    step = 0.01\n",
    "    points = []\n",
    "\n",
    "    for i in np.arange(0, 1, step):\n",
    "        for j in np.arange(0, 1, step):\n",
    "            discr = max([(id_, c_online.discriminators[id_].matching(\n",
    "                c_online.addressing((i, j)))) for id_ in discr_ids], key=lambda x: x[1])\n",
    "            c = color_dict[discr[0]]\n",
    "            if discr[1] > c_online.epsilon:\n",
    "                points.append(((i, j), c))\n",
    "    plt.scatter([point[0][0] for point in points],\n",
    "                          [point[0][1] for point in points],\n",
    "                          marker=\"s\",\n",
    "                          s=1.5,\n",
    "                          c=[point[1] for point in points])\n",
    "    plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_areas([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epsilon_areas([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot results of online vs offline clustering\n",
    "%matplotlib inline\n",
    "\n",
    "# Online\n",
    "plt.figure(1, figsize=(6,6))\n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    plt.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[int(k)])\n",
    "    plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "plt.suptitle('Online Clustering', fontsize=18)\n",
    "    \n",
    "# Offline1\n",
    "plt.figure(2, figsize=(6,6))        \n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    correct = return_correct(k, actual_clusters1)\n",
    "    plt.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[correct])\n",
    "plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "plt.suptitle('1. Offline Clustering', fontsize=18)\n",
    "\n",
    "# Offline2\n",
    "plt.figure(3, figsize=(6,6))        \n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    correct = return_correct(k, actual_clusters2)\n",
    "    plt.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[correct])\n",
    "plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "plt.suptitle('2. Offline Clustering', fontsize=18)\n",
    "\n",
    "# Offline3\n",
    "plt.figure(4, figsize=(6,6))        \n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    correct = return_correct(k, actual_clusters3)\n",
    "    plt.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[correct])\n",
    "plt.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "plt.suptitle('3. Offline Clustering', fontsize=18)\n",
    "    \n",
    "print(\"Found {} Microclusters and formed {}, {}, {} Clusters.\".format(len(c_online.discriminators), len(actual_clusters1), len(actual_clusters2), len(actual_clusters3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Homogeneity, Completeness, V-Measure of clusterings\n",
    "print(\"Homogeneity, Completeness, V-Measure\")\n",
    "\n",
    "# Online\n",
    "print(\"Online: \", homogeneity_completeness_v_measure(datastream[\"Class\"], assigned_discriminators))\n",
    "\n",
    "# Offline\n",
    "print(\"Offline1: \", homogeneity_completeness_v_measure(datastream[\"Class\"], [return_correct(assigned_discriminators[i], actual_clusters1) for i in range(len(assigned_discriminators))]))\n",
    "print(\"Offline2: \", homogeneity_completeness_v_measure(datastream[\"Class\"], [return_correct(assigned_discriminators[i], actual_clusters2) for i in range(len(assigned_discriminators))]))\n",
    "print(\"Offline3: \", homogeneity_completeness_v_measure(datastream[\"Class\"], [return_correct(assigned_discriminators[i], actual_clusters3) for i in range(len(assigned_discriminators))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell visualizes the behavior of the online clustering over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live online clustering plot\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "ax.axis('scaled', xlim=[0, 1, 0, 1])\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i in range(len(assigned_discriminators)):\n",
    "    k = assigned_discriminators[i]\n",
    "    ax.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict[int(k)])\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma: Resolution of binary encoding; unterteilt jede dimension in gamma subräume/abschnitte\n",
    "Je höher, desto kleiner die epsilon area.\n",
    "\n",
    "Delta: Bestimmt anzahl der Neuronen; Gibt an wie viele verschiedene Epsilonzonen es gibt (ohne 0%)\n",
    "Je höher, desto größer die epsilon area.\n",
    "\n",
    "Area gelichbeliben bei gelichem gamm delta verhältnis?!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
