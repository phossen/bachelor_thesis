{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with WCDS\n",
    "This notebook contains all experiments that are done using WCDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wcds.wcds import WCDS\n",
    "from wcds.clusterers import *\n",
    "from sklearn.preprocessing import minmax_scale, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import *\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import io\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data sets\n",
    "In the following sections `datastream` will be the variable storing the current data stream. It uses a pandas dataframe for that. The last column contains the instance's class for evaluation and should not be passed to the algorithm.\n",
    "\n",
    "By executing one of the following cells, the chosen data set/stream will be loaded.\n",
    "\n",
    "2D data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex8\n",
    "url = \"http://www2.cs.uh.edu/~ml_kdd/restored/Complex&Diamond/Complex8.data\"\n",
    "datastream = pd.read_csv(url, names=["X", "Y", \"Class\"], header=None)\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex9\n",
    "url = \"http://www2.cs.uh.edu/~ml_kdd/restored/Complex&Diamond/Complex9.txt\"\n",
    "datastream = pd.read_csv(url, names=["X", "Y", \"Class\"], header=None)\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D31\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/D31.txt\"\n",
    "datastream = pd.read_csv(url, names=["X", "Y", \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jain\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/jain.txt\"\n",
    "datastream = pd.read_csv(url, names=["X", "Y", \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation\n",
    "url = \"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"\n",
    "datastream = pd.read_csv(url, names=["X", "Y", \"Class\"], header=None, sep=\"\\t\")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream = datastream.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data streams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transient Chess Board\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/chess/transientChessboard.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/chess/transientChessboard.labels\"\n",
    "datastream = pd.read_csv(url_data, names=["X", "Y"], header=None, sep=\" \")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Squares\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/movingSquares/movingSquares.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/movingSquares/movingSquares.labels\"\n",
    "datastream = pd.read_csv(url_data, names=["X", "Y"], header=None, sep=\" \")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interchangin RBF\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/rbf/interchangingRBF.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/rbf/interchangingRBF.labels\"\n",
    "datastream = pd.read_csv(url_data, names=["X", "Y"], header=None, sep=\" \")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving RBF\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/rbf/movingRBF.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/rbf/movingRBF.labels\"\n",
    "datastream = pd.read_csv(url_data, header=None, sep=\" \")\n",
    "scaler = MinMaxScaler()\n",
    "datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed Drift\n",
    "url_data = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/mixedDrift/mixedDrift.data\"\n",
    "url_labels = \"https://raw.githubusercontent.com/vlosing/driftDatasets/master/artificial/mixedDrift/mixedDrift.labels\"\n",
    "datastream = pd.read_csv(url_data, names=["X", "Y"], header=None, sep=\" \")\n",
    "datastream[\"X\"] = minmax_scale(datastream[\"X\"])\n",
    "datastream[\"Y\"] = minmax_scale(datastream[\"Y\"])\n",
    "datastream[\"Class\"] = pd.read_csv(url_labels, names=[\"Class\"], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEA Concepts\n",
    "datastream = pd.read_csv(\"../Datasets/sea.data\", header=None)\n",
    "labels = datastream.iloc[:, 3]\n",
    "datastream = datastream.drop(columns=[3])\n",
    "scaler = MinMaxScaler()\n",
    "datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)\n",
    "datastream[\"Class\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Supply Data Stream\n",
    "url = \"http://www.cse.fau.edu/~xqzhu/Stream/powersupply.arff\"\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "data, meta = arff.loadarff(io.StringIO(ftpstream.read().decode('utf-8')))\n",
    "datastream = pd.DataFrame(data)\n",
    "datastream[\"attribute0\"] = minmax_scale(datastream[\"attribute0\"])\n",
    "datastream[\"attribute1\"] = minmax_scale(datastream[\"attribute1\"])\n",
    "datastream[\"Class\"] = [int(obs) for obs in datastream[\"class\"]]\n",
    "datastream = datastream.drop(columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of Network Intrusion Detection (KDD Cup 1999)\n",
    "url = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\n",
    "header = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\",\n",
    "    \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n",
    "    \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\",\n",
    "    \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
    "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
    "    \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
    "    \"dst_host_srv_rerror_rate\", \"Class\"]\n",
    "datastream = pd.read_csv(url, names=header, header=None)\n",
    "label_encoder = LabelEncoder() \n",
    "classes = label_encoder.fit_transform(datastream["Class"]) \n",
    "datastream = datastream.select_dtypes(exclude=[\"object\"])\n",
    "datastream = datastream.drop(columns=[\"land\", \"logged_in\", \"is_host_login\", \"is_guest_login\"])\n",
    "scaler = MinMaxScaler()\n",
    "datastream = pd.DataFrame(scaler.fit_transform(datastream), columns=datastream.columns)\n",
    "datastream[\"Class\"] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest Cover Type\n",
    "data = arff.loadarff("../Datasets/covtypeNorm.arff")\n",
    "datastream = pd.DataFrame(data[0])\n",
    "labels = datastream[\"class\"].astype(int)\n",
    "datastream = datastream.select_dtypes(exclude=\"O\")\n",
    "datastream[\"Class\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first rows of the data set and its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datastream.head())\n",
    "print(datastream.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering 2D data sets\n",
    "### 2.1 Online clustering\n",
    "The next step is to perform the online step of stream clustering with WCDS on the previous selected `datastream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parameters\n",
    "OMEGA = math.inf\n",
    "DELTA = 200\n",
    "GAMMA = 200\n",
    "BETA = 60\n",
    "EPSILON = 0.1\n",
    "µ = 0\n",
    "DIM = len(datastream.iloc[0])-1\n",
    "time_ = 0\n",
    "eval_step = 100\n",
    "\n",
    "# Clusterer instance\n",
    "c_online = WCDS(\n",
    "    omega=OMEGA,\n",
    "    delta=DELTA,\n",
    "    gamma=GAMMA,\n",
    "    epsilon=EPSILON,\n",
    "    dimension=DIM,\n",
    "    beta=BETA,\n",
    "    µ=µ)\n",
    "\n",
    "# Lists\n",
    "assigned_discriminators = []\n",
    "number_discriminators = []\n",
    "\n",
    "# Online step\n",
    "for i in range(len(datastream)):\n",
    "    k, _ = c_online.record(list(datastream.iloc[i])[:-1], time_)\n",
    "    number_discriminators.append(len(c_online.discriminators))\n",
    "    assigned_discriminators.append(k)\n",
    "    time_ += 1\n",
    "    if i % eval_step == 0 and i > 0:\n",
    "        print(\"Observation: {} #Discriminators: {} Cluster Measures: {}\".format(i, len(c_online), homogeneity_completeness_v_measure(datastream[\"Class\"][max(i-eval_step, 0):i], assigned_discriminators[max(i-eval_step, 0):i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional save\n",
    "c_online.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Offline clustering\n",
    "Now we perform offline clustering on the current configuration of WCDS. There are three variants, but the first one is the one presented in the original paper and therefore performs best most of the times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 2\n",
    "THRESHOLD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# MergeClustering\n",
    "\n",
    "c_offline = MergeClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "actual_clusters1 = c_offline.fit(c_online.discriminators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# MinDistanceClustering\n",
    "\n",
    "c_offline = MinDistanceClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "actual_clusters2 = c_offline.fit(c_online.discriminators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# CentroidClustering\n",
    "\n",
    "c_offline = CentroidClustering(n_clusters=N_CLUSTERS, distance_threshold=THRESHOLD)\n",
    "centroids = [c_online.centroid(d) for d in c_online.discriminators.values()]\n",
    "actual_clusters3 = c_offline.fit(c_online.discriminators, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Results\n",
    "The following section visualizes and summarizes the obtained results.\n",
    "\n",
    "| Data set | #Instances | Dimensions | Homogenity | Completeness | V-Measure | #Microclusters | Omega | Delta | Gamma | Beta | Epsilon | Mu | Runtime Online |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Complex8 | 2551 | 2 | 0.9053588976743742 | 0.9335710366851351 | 0.9192485574153881 | 91 | Inf | 200 | 200 | 70 | 0.1 | 0 | 24min 46s |\n",
    "| Complex9 | 3031 | 2 | 0.9050691859653084 | 0.8300021530934564 | 0.8659117998655447 | 98 | Inf | 200 | 200 | 80 | 0.1 | 0 | 21min 22s |\n",
    "| D31 | 3100 | 2 | 0.9055106871046765 | 0.9517232533653724 | 0.9280420288574567 | 44 | Inf | 200 | 200 | 30 | 0.3 | 0 | 5min 24s |\n",
    "| Jain | 373 | 2 | 1.0 | 1.0 | 1.0 | 33 | Inf | 200 | 200 | 60 | 0.1 | 0 | 35.7 s |\n",
    "| Aggregation | 788 | 2 | 0.9888391642302382 | 0.9876953626611313 | 0.9882669324921871 | 38 | Inf | 200 | 200 | 50 | 0.1 | 0 | 1min 43s |\n",
    "\n",
    "Plot results of online vs offline clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_dict(i, shift=0):\n",
    "    color = \"#\"\n",
    "    random.seed(i+shift)\n",
    "    color += "".join(random.choices("0123456789ABCDEF", k=6))\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Online\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(datastream[\"X\"], datastream[\"Y\"], marker=\"o\", color=[color_dict(ass) for ass in assigned_discriminators])\n",
    "plt.axis("scaled", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle("Online Clustering", fontsize=18)\n",
    "print(\"Found {} Microclusters\".format(len(c_online)))\n",
    "print(\"Homogenity/Completeness/V-Measure: \", homogeneity_completeness_v_measure(datastream[\"Class\"], assigned_discriminators))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Offline1\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(datastream[\"X\"], datastream[\"Y\"], marker=\"o\", color=[color_dict(actual_clusters1[ass]) for ass in assigned_discriminators])\n",
    "plt.axis("scaled", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle("1. Offline Clustering", fontsize=18)\n",
    "print(\"Formed {} Clusters.\".format(len(np.unique(list(actual_clusters1.values())))))\n",
    "print(\"Homogenity/Completeness/V-Measure: \", homogeneity_completeness_v_measure(datastream[\"Class\"], [actual_clusters1[ass] for ass in assigned_discriminators]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Offline2\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(datastream[\"X\"], datastream[\"Y\"], marker=\"o\", color=[color_dict(actual_clusters2[ass]) for ass in assigned_discriminators])\n",
    "plt.axis("scaled", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle("2. Offline Clustering", fontsize=18)\n",
    "print(\"Formed {} Clusters.\".format(len(np.unique(list(actual_clusters2.values())))))\n",
    "print(\"Homogenity/Completeness/V-Measure: \", homogeneity_completeness_v_measure(datastream[\"Class\"], [actual_clusters2[ass] for ass in assigned_discriminators]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Offline3\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(datastream[\"X\"], datastream[\"Y\"], marker=\"o\", color=[color_dict(actual_clusters3[ass]) for ass in assigned_discriminators])\n",
    "plt.axis("scaled", xlim=[0, 1, 0, 1])\n",
    "plt.suptitle("3. Offline Clustering", fontsize=18)\n",
    "print(\"Formed {} Clusters.\".format(len(np.unique(list(actual_clusters3.values())))))\n",
    "print(\"Homogenity/Completeness/V-Measure: \", homogeneity_completeness_v_measure(datastream[\"Class\"], [actual_clusters3[ass] for ass in assigned_discriminators]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell visualizes the behavior of the online clustering over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live online clustering plot\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "ax.axis("scaled", xlim=[0, 1, 0, 1])\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i in range(len(assigned_discriminators)):\n",
    "    ax.scatter(datastream[\"X\"][i], datastream[\"Y\"][i], marker=\"o\", color=color_dict(int(assigned_discriminators[i])))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stream clustering\n",
    "### 3.1 Online and offline clustering\n",
    "This part contains the online and offline clustering of the loaded data stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parameters\n",
    "OMEGA = 120\n",
    "DELTA = 50\n",
    "GAMMA = 50\n",
    "BETA = 70\n",
    "EPSILON = 0.1\n",
    "µ = 1\n",
    "DIM = len(datastream.iloc[0])-1\n",
    "time_ = 0\n",
    "eval_step = OMEGA\n",
    "\n",
    "# Clusterer instance\n",
    "c_online = WCDS(\n",
    "    omega=OMEGA,\n",
    "    delta=DELTA,\n",
    "    gamma=GAMMA,\n",
    "    epsilon=EPSILON,\n",
    "    dimension=DIM,\n",
    "    beta=BETA,\n",
    "    µ=µ)\n",
    "\n",
    "# Lists\n",
    "assigned_discriminators = []\n",
    "number_discriminators = []\n",
    "eval_values = []\n",
    "discriminator_lifespan = dict()\n",
    "\n",
    "# Online clustering\n",
    "for i in range(len(datastream)):\n",
    "    k, deleted_discriminators = c_online.record(list(datastream.iloc[i])[:-1], time_)\n",
    "    if k not in discriminator_lifespan:\n",
    "        discriminator_lifespan[k] = [c_online.discriminators[k].creation_time, None]\n",
    "    for id_ in deleted_discriminators:\n",
    "        discriminator_lifespan[id_][1] = time_\n",
    "    number_discriminators.append(len(c_online.discriminators))\n",
    "    assigned_discriminators.append(k)\n",
    "    time_ += 1\n",
    "    if i % eval_step == 0 and i > 0:\n",
    "        current_evaluation = homogeneity_completeness_v_measure(datastream[\"Class\"][max(i-eval_step, 0):i], assigned_discriminators[max(i-eval_step, 0):i])\n",
    "        eval_values.append(current_evaluation)\n",
    "        print(\"Observation: {} #Discriminators: {} Online Cluster Measures: {}\".format(i, len(c_online), current_evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Results\n",
    "Visualisations and results of the experiments.\n",
    "\n",
    "| Data set | #Instances | Dimensions | Omega | Delta | Gamma | Beta | Epsilon | Mu | Runtime Online |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Chessboard | 200000 | 2 | 300 | 100 | 100 | 50 | 0.1 | 1 | ? |\n",
    "| Moving Squares | /200000 | 2 | 120 | 100 | 100 | 60 | 0.1 | 1 | ? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_dict(i, shift=0):\n",
    "    color = \"#\"\n",
    "    random.seed(i+shift)\n",
    "    color += "".join(random.choices("0123456789ABCDEF", k=6))\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Lifespans\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "for k in discriminator_lifespan:\n",
    "    if discriminator_lifespan[k][1] is None:\n",
    "        discriminator_lifespan[k][1] = time_\n",
    "    plt.plot(range(discriminator_lifespan[k][0], discriminator_lifespan[k][1]), [k for _ in range(discriminator_lifespan[k][0], discriminator_lifespan[k][1])])\n",
    "plt.suptitle("Discriminator Lifespan", fontsize=18)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Discriminator ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Homogenity\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "x = range(eval_step, time_, eval_step)\n",
    "y = [i[0] for i in eval_values]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"# Examples\")\n",
    "plt.ylabel(\"Homogenity\")\n",
    "plt.ylim(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot #Discriminators vs #Of classes in sliding window\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "plt.plot(number_discriminators)\n",
    "plt.plot([len(np.unique(datastream[\"Class\"][i:i+OMEGA])) for i in range(len(number_discriminators)-OMEGA)])\n",
    "plt.xlabel(\"# Examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live plot of the sliding windows, only works for 2D\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1)\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for window in range(eval_step, time_, eval_step):\n",
    "    ax.clear()\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.scatter(datastream[\"X\"][window:window+eval_step], datastream[\"Y\"][window:window+eval_step], color=[color_dict(datastream[\"Class\"][i]) for i in range(window,window+eval_step)])\n",
    "    fig.canvas.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
